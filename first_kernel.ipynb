{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mplimg\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from keras import layers\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.applications import inception_v3\n",
    "from keras.layers import Input, Dense, Activation, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalAveragePooling2D, LeakyReLU\n",
    "from keras.models import Model, load_model\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "import cv2\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['all.zip',\n",
       " 'crop_test',\n",
       " 'crop_train',\n",
       " 'model-files',\n",
       " 'sample_submission.csv',\n",
       " 'test',\n",
       " 'test.zip',\n",
       " 'train',\n",
       " 'train.csv',\n",
       " 'train.zip']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"../dados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000e88ab.jpg</td>\n",
       "      <td>w_f48451c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001f9222.jpg</td>\n",
       "      <td>w_c3d896a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00029d126.jpg</td>\n",
       "      <td>w_20df2c5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00050a15a.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0005c1ef8.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Image         Id\n",
       "0  0000e88ab.jpg  w_f48451c\n",
       "1  0001f9222.jpg  w_c3d896a\n",
       "2  00029d126.jpg  w_20df2c5\n",
       "3  00050a15a.jpg  new_whale\n",
       "4  0005c1ef8.jpg  new_whale"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"../dados/train.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25361"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_FOLDER = '../dados/train/'\n",
    "TEST_FOLDER = '../dados/test/'\n",
    "bouding = pd.read_csv(\"bounding_boxes.csv\")\n",
    "load_X = []\n",
    "load_Y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>x0</th>\n",
       "      <th>y0</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000e88ab.jpg</td>\n",
       "      <td>223.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>860.0</td>\n",
       "      <td>438.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001f9222.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>744.0</td>\n",
       "      <td>243.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00029d126.jpg</td>\n",
       "      <td>26.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>464.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00050a15a.jpg</td>\n",
       "      <td>17.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>413.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0005c1ef8.jpg</td>\n",
       "      <td>72.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>879.0</td>\n",
       "      <td>310.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Image     x0     y0      x1     y1\n",
       "0  0000e88ab.jpg  223.0  149.0   860.0  438.0\n",
       "1  0001f9222.jpg    1.0   77.0   744.0  243.0\n",
       "2  00029d126.jpg   26.0   19.0  1027.0  464.0\n",
       "3  00050a15a.jpg   17.0  153.0  1012.0  413.0\n",
       "4  0005c1ef8.jpg   72.0  186.0   879.0  310.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bouding.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>x0</th>\n",
       "      <th>y0</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000e88ab.jpg</td>\n",
       "      <td>223.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>860.0</td>\n",
       "      <td>438.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Image     x0     y0     x1     y1\n",
       "0  0000e88ab.jpg  223.0  149.0  860.0  438.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bouding.loc[bouding['Image'] == '0000e88ab.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for img in sorted(os.listdir(TRAIN_FOLDER)):\n",
    "    if img.split('.')[1] in ['jpg', 'jpeg']:\n",
    "        #try:\n",
    "        load_X.append(TRAIN_FOLDER + img)\n",
    "        load_Y.append(train_df[train_df.Image == img].Id.tolist()[0])\n",
    "        #except:\n",
    "            #print(img)\n",
    "            #print(train_df[train_df.Image == img].Id.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from imgaug import augmenters as iaa\n",
    "import imgaug as ia\n",
    "\n",
    "sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
    "\n",
    "\n",
    "seq = iaa.Sequential([\n",
    "    #sometimes(iaa.Invert(p=1)),\n",
    "    iaa.ContrastNormalization(alpha=(0.8,1.2)),\n",
    "    iaa.Fliplr(0.5),\n",
    "    iaa.Flipud(0.2),\n",
    "    \n",
    "    iaa.GaussianBlur(sigma=(0, 1.0)),# blur images with a sigma of 0 to 3.0\n",
    "    iaa.AdditiveGaussianNoise(scale=(0,0.05*225)),\n",
    "    iaa.Affine(\n",
    "            scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)}, # scale images to 80-120% of their size, individually per axis\n",
    "            translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)}, # translate by -20 to +20 percent (per axis)\n",
    "            rotate=(0, 360), # rotate by -45 to +45 degrees\n",
    "            shear=(-16, 16), # shear by -16 to +16 degrees\n",
    "            order=[0, 1], # use nearest neighbour or bilinear interpolation (fast)\n",
    "            cval=(0, 255), # if mode is constant, use a cval between 0 and 255\n",
    "            mode=ia.ALL # use any of scikit-image's warping modes (see 2nd image from the top for examples)\n",
    "        )\n",
    "   \n",
    " \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "class Generator:\n",
    "    def __init__(self, size, batch_size):\n",
    "        self.X_train = load_X\n",
    "        self.Y_train = load_Y \n",
    "        self.X_train, self.Y_train = shuffle(self.X_train, self.Y_train)\n",
    "        self.len = len(self.X_train)\n",
    "        self.cur_index = 0\n",
    "        self.size = size\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        integer_encoded = self.label_encoder.fit_transform(self.Y_train)\n",
    "        # print(integer_encoded)\n",
    "\n",
    "        onehot_encoder = OneHotEncoder(sparse=False)\n",
    "        integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "        onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "        # print(onehot_encoded)\n",
    "\n",
    "        self.Y_train = onehot_encoded\n",
    "        \n",
    "    def preprocess(self, batch_img_path):\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            imgs = np.ones([self.batch_size, 3, self.size, self.size])\n",
    "        else:\n",
    "            imgs = np.ones([self.batch_size, self.size, self.size, 3])\n",
    "            \n",
    "        for i, path in enumerate(batch_img_path):\n",
    "            #try:\n",
    "            img = cv2.imread(path)\n",
    "            #img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            #adicionar imgaug\n",
    "            \n",
    "            #Cropping\n",
    "            img_name = path.rsplit('/')[1]\n",
    "            res = bouding.loc[bouding['Image'] == img_name]\n",
    "            if len(res.y0.tolist()) > 0 and len(res.y1.tolist()) > 0 and len(res.x1.tolist()) > 0 and len(res.x0.tolist()) > 0:\n",
    "                img = img[int(res.y0.tolist()[0]):int(res.y1.tolist()[0]) , int(res.x0.tolist()[0]):int(res.x1.tolist()[0])]\n",
    "            \n",
    "            img = cv2.resize(img, (self.size, self.size))\n",
    "            img = seq.augment_images(np.array([img]))\n",
    "            img = img.astype(np.float32) / 255.0\n",
    "\n",
    "            #if K.image_data_format() == 'channels_first':\n",
    "            #    img = np.expand_dims(img, 0)\n",
    "            #else:\n",
    "            #    img = np.expand_dims(img, -1)\n",
    "\n",
    "            imgs[i,:,:] = img\n",
    "            #except:\n",
    "                #print(img)\n",
    "                \n",
    "        return imgs\n",
    "                \n",
    "                \n",
    "    def getBatch(self):\n",
    "        while True:\n",
    "            stop_batch = self.cur_index + self.batch_size\n",
    "            \n",
    "            if stop_batch <= self.len:\n",
    "                batch_img_path = self.X_train[self.cur_index: stop_batch]\n",
    "                X_data = self.preprocess(batch_img_path)\n",
    "                Y_data = self.Y_train[self.cur_index: stop_batch]\n",
    "                self.cur_index += self.batch_size\n",
    "            else:\n",
    "                self.cur_index = self.cur_index % self.batch_size\n",
    "                batch_img_path = self.X_train[self.cur_index: (self.cur_index + self.batch_size)]\n",
    "                X_data = self.preprocess(batch_img_path)\n",
    "                Y_data = self.Y_train[self.cur_index: (self.cur_index + self.batch_size)]\n",
    "                self.cur_index += self.batch_size\n",
    "                \n",
    "            yield (X_data, Y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "def prepareImages(data, m, dataset,size):\n",
    "    print(\"Preparing images\")\n",
    "    X_train = np.zeros((m, size, size, 3))\n",
    "    count = 0\n",
    "    \n",
    "    for fig in data['Image']:\n",
    "        #load images into images of size 100x100x3\n",
    "        #img = image.load_img(\"../dados/\"+dataset+\"/\"+fig, target_size=(128, 128, 1))\n",
    "        #img = Image.open(\"../dados/\"+dataset+\"/\"+fig)\n",
    "        #img = img.resize((128, 128), Image.ANTIALIAS)\n",
    "        #img = img.convert(\"L\")\n",
    "        #img = cv2.imread(\"../dados/\"+dataset+\"/\"+fig)\n",
    "        #img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        #img = cv2.resize(img, (64, 64))\n",
    "        \n",
    "        imgPath = \"../dados/\"+dataset+\"/\"+fig\n",
    "        \n",
    "        img = cv2.imread(imgPath)\n",
    "        img_name = imgPath.rsplit('/')[1]\n",
    "        res = bouding.loc[bouding['Image'] == img_name]\n",
    "        if len(res.y0.tolist()) > 0 and len(res.y1.tolist()) > 0 and len(res.x1.tolist()) > 0 and len(res.x0.tolist()) > 0:\n",
    "            img = img[int(res.y0.tolist()[0]):int(res.y1.tolist()[0]) , int(res.x0.tolist()[0]):int(res.x1.tolist()[0])]\n",
    "            \n",
    "        img = cv2.resize(img, (size, size))\n",
    "        x = image.img_to_array(img)\n",
    "        x = preprocess_input(x)\n",
    "\n",
    "        X_train[count] = x\n",
    "        if (count%500 == 0):\n",
    "            print(\"Processing image: \", count+1, \", \", fig)\n",
    "        count += 1\n",
    "    \n",
    "    return X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_labels(y):\n",
    "    values = np.array(y)\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(values)\n",
    "    # print(integer_encoded)\n",
    "\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "    # print(onehot_encoded)\n",
    "\n",
    "    y = onehot_encoded\n",
    "    print(y.shape)\n",
    "    return y, label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing images\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot cast ufunc subtract output from dtype('float64') to dtype('uint8') with casting rule 'same_kind'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-3e586c750b19>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprepareImages\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"crop_train\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#X /= 255\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-61f9d79441ef>\u001b[0m in \u001b[0;36mprepareImages\u001b[1;34m(data, m, dataset)\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;31m#x = image.img_to_array(img)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\bin\\anaconda3\\lib\\site-packages\\keras\\applications\\imagenet_utils.py\u001b[0m in \u001b[0;36mpreprocess_input\u001b[1;34m(x, data_format, mode)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_preprocess_numpy_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m         return _preprocess_symbolic_input(x, data_format=data_format,\n",
      "\u001b[1;32mC:\\bin\\anaconda3\\lib\\site-packages\\keras\\applications\\imagenet_utils.py\u001b[0m in \u001b[0;36m_preprocess_numpy_input\u001b[1;34m(x, data_format, mode)\u001b[0m\n\u001b[0;32m     80\u001b[0m                 \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[0mstd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot cast ufunc subtract output from dtype('float64') to dtype('uint8') with casting rule 'same_kind'"
     ]
    }
   ],
   "source": [
    "X = prepareImages(train_df, train_df.shape[0], \"crop_train\")\n",
    "#X /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25361, 5005)\n"
     ]
    }
   ],
   "source": [
    "y, label_encoder = prepare_labels(train_df['Id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5004"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y, test_size = 0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.optimizers.Adam at 0x26c48f7d828>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.optimizers import SGD, Adadelta, Nadam, Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "opt = SGD(lr=0.0001)\n",
    "nd = Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0)\n",
    "Adam(lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_gen = Generator(197, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape = (train_gen.size, train_gen.size,3), pooling='no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(32)(x)\n",
    "x = LeakyReLU()(x)\n",
    "#x = Conv2D(32, (3, 3), strides = (1, 1), input_shape = (197, 197, 3))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "#x = Activation('relu')(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(8)(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.4)(x)\n",
    "x = Dense(1000, activation='relu')(x)\n",
    "# and a logistic layer -- let's say we have 200 classes\n",
    "predictions = Dense(train_gen.Y_train.shape[1], activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/14\n",
      " 354/1811 [====>.........................] - ETA: 51:45 - loss: 6.4340 - acc: 0.3822"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-0aabba7d4ff0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m history = model.fit_generator(train_gen.getBatch(), steps_per_epoch=train_gen.len / train_gen.batch_size, epochs=14, verbose=1, callbacks=[\n\u001b[0;32m     10\u001b[0m             \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_delta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[0mReduceLROnPlateau\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_delta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_lr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.002\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         ])\n\u001b[0;32m     13\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"novomodel.model\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\bin\\anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\bin\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2228\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[0;32m   2229\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2230\u001b[1;33m                                                class_weight=class_weight)\n\u001b[0m\u001b[0;32m   2231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2232\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\bin\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1881\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1882\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1883\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1884\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1885\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\bin\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2482\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2483\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\bin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\bin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\bin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\bin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\bin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\bin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_gen.getBatch(), steps_per_epoch=train_gen.len / train_gen.batch_size, epochs=14, verbose=1, callbacks=[\n",
    "            EarlyStopping(monitor='val_acc', patience=20, min_delta=0.01, verbose=1),\n",
    "            ReduceLROnPlateau(monitor='val_acc', patience=3, min_delta=0.1, factor=0.25, min_lr=0.002, verbose=1)\n",
    "        ])\n",
    "model.save(\"novomodel.model\")\n",
    "#gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7960\n"
     ]
    }
   ],
   "source": [
    "test = os.listdir(\"../dados/test/\")\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col = ['Image']\n",
    "test_df = pd.DataFrame(test, columns=col)\n",
    "test_df['Id'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7960"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_df = test_df.iloc[0:2000]\n",
    "second_df = test_df.iloc[2001:4000]\n",
    "third_df = test_df.iloc[4001:6000]\n",
    "forth_df = test_df.iloc[6001:test_df.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1959"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forth_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model('novomodel.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def processByStep(dataFrame, size, first_index):\n",
    "    X = prepareImages(dataFrame, dataFrame.shape[0], \"test\", size)\n",
    "    X /= 255\n",
    "    predictions = model.predict(np.array(X), verbose=1)\n",
    "    for i, pred in enumerate(predictions):\n",
    "        test_df.loc[i + first_index, 'Id'] = ' '.join(label_encoder.inverse_transform(pred.argsort()[-5:][::-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing images\n",
      "Processing image:  1 ,  00028a005.jpg\n",
      "Processing image:  501 ,  0f9219c40.jpg\n",
      "Processing image:  1001 ,  1ea95c247.jpg\n",
      "Processing image:  1501 ,  2fe4ec2d5.jpg\n",
      "2000/2000 [==============================] - 107s 54ms/step\n",
      "Preparing images\n",
      "Processing image:  1 ,  4043c4a1d.jpg\n",
      "Processing image:  501 ,  4fe483e96.jpg\n",
      "Processing image:  1001 ,  6005a13de.jpg\n",
      "Processing image:  1501 ,  70438d9d1.jpg\n",
      "1999/1999 [==============================] - 102s 51ms/step\n",
      "Preparing images\n",
      "Processing image:  1 ,  802330ff6.jpg\n",
      "Processing image:  501 ,  906b3c9c3.jpg\n",
      "Processing image:  1001 ,  a0d962939.jpg\n",
      "Processing image:  1501 ,  b1aa98e8c.jpg\n",
      "1999/1999 [==============================] - 100s 50ms/step\n",
      "Preparing images\n",
      "Processing image:  1 ,  c0bbbf064.jpg\n",
      "Processing image:  501 ,  cfeae6723.jpg\n",
      "Processing image:  1001 ,  e00b17e08.jpg\n",
      "Processing image:  1501 ,  f1b73b091.jpg\n",
      "1959/1959 [==============================] - 102s 52ms/step\n"
     ]
    }
   ],
   "source": [
    "processByStep(first_df, 197, 0)\n",
    "processByStep(second_df, 197, 2001)\n",
    "processByStep(third_df, 197, 4001)\n",
    "processByStep(forth_df, 197, 6001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing images\n",
      "Processing image:  1 ,  00028a005.jpg\n",
      "Processing image:  501 ,  0f9219c40.jpg\n",
      "Processing image:  1001 ,  1ea95c247.jpg\n",
      "Processing image:  1501 ,  2fe4ec2d5.jpg\n",
      "Processing image:  2001 ,  404206f77.jpg\n",
      "Processing image:  2501 ,  4fc69fd82.jpg\n",
      "Processing image:  3001 ,  5ffc2d300.jpg\n",
      "Processing image:  3501 ,  7042be267.jpg\n",
      "Processing image:  4001 ,  801c6a722.jpg\n",
      "Processing image:  4501 ,  906aa36c8.jpg\n",
      "Processing image:  5001 ,  a0d337cdc.jpg\n",
      "Processing image:  5501 ,  b1a4e4c18.jpg\n",
      "Processing image:  6001 ,  c0b378682.jpg\n",
      "Processing image:  6501 ,  cfe9d9d04.jpg\n",
      "Processing image:  7001 ,  e00620fc3.jpg\n",
      "Processing image:  7501 ,  f1b504951.jpg\n"
     ]
    }
   ],
   "source": [
    "X = prepareImages(test_df, test_df.shape[0], \"test\", 197)\n",
    "X /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model('novomodel.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-cb22705009f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "predictions = model.predict(np.array(X), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, pred in enumerate(predictions):\n",
    "    test_df.loc[i, 'Id'] = ' '.join(label_encoder.inverse_transform(pred.argsort()[-5:][::-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df.to_csv('submission_resnet50.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00028a005.jpg</td>\n",
       "      <td>new_whale w_81d4bd6 w_69b5ace w_c01c1f4 w_9a9a2c8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000dcf7d8.jpg</td>\n",
       "      <td>new_whale w_81d4bd6 w_69b5ace w_c01c1f4 w_04003e9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000e7c7df.jpg</td>\n",
       "      <td>new_whale w_81d4bd6 w_69b5ace w_89f521e w_9a9a2c8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0019c34f4.jpg</td>\n",
       "      <td>new_whale w_81d4bd6 w_69b5ace w_04003e9 w_df32eec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001a4d292.jpg</td>\n",
       "      <td>new_whale w_81d4bd6 w_69b5ace w_c01c1f4 w_9a9a2c8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00247bc36.jpg</td>\n",
       "      <td>new_whale w_81d4bd6 w_69b5ace w_89f521e w_9a9a2c8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0027089a4.jpg</td>\n",
       "      <td>new_whale w_81d4bd6 w_69b5ace w_89f521e w_9a9a2c8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>002de4d94.jpg</td>\n",
       "      <td>new_whale w_81d4bd6 w_69b5ace w_04003e9 w_df32eec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>002f52f0c.jpg</td>\n",
       "      <td>new_whale w_81d4bd6 w_69b5ace w_df32eec w_c01c1f4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>002fd89d4.jpg</td>\n",
       "      <td>new_whale w_81d4bd6 w_69b5ace w_c01c1f4 w_04003e9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Image                                                 Id\n",
       "0  00028a005.jpg  new_whale w_81d4bd6 w_69b5ace w_c01c1f4 w_9a9a2c8\n",
       "1  000dcf7d8.jpg  new_whale w_81d4bd6 w_69b5ace w_c01c1f4 w_04003e9\n",
       "2  000e7c7df.jpg  new_whale w_81d4bd6 w_69b5ace w_89f521e w_9a9a2c8\n",
       "3  0019c34f4.jpg  new_whale w_81d4bd6 w_69b5ace w_04003e9 w_df32eec\n",
       "4  001a4d292.jpg  new_whale w_81d4bd6 w_69b5ace w_c01c1f4 w_9a9a2c8\n",
       "5  00247bc36.jpg  new_whale w_81d4bd6 w_69b5ace w_89f521e w_9a9a2c8\n",
       "6  0027089a4.jpg  new_whale w_81d4bd6 w_69b5ace w_89f521e w_9a9a2c8\n",
       "7  002de4d94.jpg  new_whale w_81d4bd6 w_69b5ace w_04003e9 w_df32eec\n",
       "8  002f52f0c.jpg  new_whale w_81d4bd6 w_69b5ace w_df32eec w_c01c1f4\n",
       "9  002fd89d4.jpg  new_whale w_81d4bd6 w_69b5ace w_c01c1f4 w_04003e9"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "new_whale    9664\n",
       "w_23a388d      73\n",
       "w_9b5109b      65\n",
       "w_9c506f6      62\n",
       "w_0369a5c      61\n",
       "w_700ebb4      57\n",
       "w_3de579a      54\n",
       "w_564a34b      51\n",
       "w_fd3e556      50\n",
       "w_88e4537      49\n",
       "w_2b069ba      48\n",
       "w_d405854      47\n",
       "w_f0fe284      45\n",
       "w_789c969      45\n",
       "w_343f088      40\n",
       "w_778e474      40\n",
       "w_5e8e218      40\n",
       "w_5a2634c      37\n",
       "w_60ce6fc      37\n",
       "w_a9304b9      37\n",
       "w_6822dbc      36\n",
       "w_af367c3      35\n",
       "w_f765256      34\n",
       "w_1ca9ab1      34\n",
       "w_17b0d3a      33\n",
       "w_d72771c      32\n",
       "w_8c25681      31\n",
       "w_6cda039      31\n",
       "w_08630fd      31\n",
       "w_51fc1fc      30\n",
       "             ... \n",
       "w_d609d41       1\n",
       "w_d44dfdc       1\n",
       "w_f08d3f7       1\n",
       "w_a1e3bc9       1\n",
       "w_567d88c       1\n",
       "w_536beda       1\n",
       "w_eb31833       1\n",
       "w_5ce4848       1\n",
       "w_6c2e008       1\n",
       "w_214e081       1\n",
       "w_b8b8383       1\n",
       "w_1d2ed91       1\n",
       "w_808d40b       1\n",
       "w_2623b69       1\n",
       "w_8261f4d       1\n",
       "w_490d198       1\n",
       "w_6d1f159       1\n",
       "w_2757c07       1\n",
       "w_fd4376a       1\n",
       "w_9e020d1       1\n",
       "w_2ac6611       1\n",
       "w_36f91ad       1\n",
       "w_6fe3566       1\n",
       "w_795a6b8       1\n",
       "w_d31f7e6       1\n",
       "w_1ff1582       1\n",
       "w_1a9e018       1\n",
       "w_dccbb2e       1\n",
       "w_398323d       1\n",
       "w_641df87       1\n",
       "Name: Id, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.Id.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
